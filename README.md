# TOFL: Time Optimized Federated Learning

Vehicular networks face cyber threats that can harm drivers, passengers, and pedestrians. In this scenario, federated learning is a possible solution to train models that detect threats without violating user privacy. However, federated learning is particularly sensitive to communication delays, which is a natural consequence of high mobility in vehicular networks. This problem is commonly ignored in the literature, which does not consider the possibility of network disconnections. This work proposes a client selection strategy designed to minimize the training time of a machine learning model for vehicular threat detection, considering the communication time that varies according to the movement of clients. The results demonstrate that TOFL, using only 20% of the total available clients, can reduce the time required to achieve high accuracy by up to 50% compared to state-of-the-art approaches, while reducing the resource consumption of client devices.

This repository contains the code developed for SBSeg 2025. The code is composed by three parts. The first part simulates vehicles mobility, to extract this pattern to estimate the user delays, on the second part, using 5G technology. Finally, the third part simulates the federated learning training, given the latency values obtained during the first and second parts. The object is to test different client selection strategies in a scenario with mobility.

# Security considerations

Our code only uses CSV files pre-processed from simulated CAM data. Therefore, this code does not impose any risk for the host during its execution.

# Considered Stamps

We aim to obtain all four stamps from the conference: available, functional, sustainable, and reproducible.


# Minimum Requirement

- SO: Ubuntu 22.04.5 LTS
- Cores: 2
- Memory: 4 GB
- Storage: 64 GB

# Virtual machine

The whole environment was virtualized to make the execution easier. You can download the virtual machine image on the following address:
```bash
https://gta.ufrj.br/~airam/tofl.ova
```

# Dependencies 

## This repository has the following dependencies: 

- Git command 2.34.1
- Python3.12
- VirtualBox 7.1.12 (for the VM execution only)
- Conda 25.5.1
- SUMO 1.24.0
- pandas 2.3.1
- numpy 1.26.4
- torch 2.3.0
- torchvision 0.18.0
- matplotlib 3.10.3
- flower 1.7.0
- tensorflow 2.19.0
- scikit-learn 1.7.1
- seaborn 0.13.2
- scikit-image 0.25.2

# Installation

## Conda

### Get the script to install miniconda
```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
```

### Change script permissions
```bash
chmod +x Miniconda3-latest-Linux-x86_64.sh
```

### Execute installation
```bash
./Miniconda3-latest-Linux-x86_64.sh
```

### Run environment
```bash
source ~/.bashrc
```

## TOFL

### Clone this repository:
```bash
git clone https://github.com/AiramL/TimeOptimizedFederatedLearning.git
```
### Change to the new directory
```bash
cd TimeOptimizedFederatedLearning
```

### Create paths:
```bash
source scripts/build/paths.sh
```
### Install dependecies:
```bash
source scripts/build/dependencies.sh
```

### Accept the terms:
During the installation of dependencies and environment you might be asked to accept the terms of conda and SUMO. Make sure to enter yes. Also, conda enmvironment must be activated after its installation.

### Create the virtual environment:
```bash
source scripts/build/env.sh
```

### Download datasets:
```bash
source scripts/build/datasets.sh
```

# Execution

All the codes were executed with root user on a virtual machine.

## Estimated execution time

The whole execution time depends on the hyperparameters chosen to the test. Therefore, we select XXX cars and XXX epochs for the minimum test, which should take around 15 minutes with those values. 

## Minimum test


We consider that the minimum test is to reproduce the figures in the paper. Therefore, we provide a simplified execution, which takes the data generated by our code. However, to test from scratch, we also provide a guide to do the complete execution, which takes a long time to generate all the requirements.

### Create SUMOs' trips (2 minutes): 
 
```bash
source scripts/run/raw/mobility.sh
```
Expected output: 
```bash
PHASE 1 -> Generating the grid topology
Success.
....... -> Copy netfile to the current directory 
....... -> Generate continuous rerouters 
....... -> Generating random flows for JTRROUTER 
....... -> Run SUMO for configuration Krauss 5 cars / iteration 0
....... -> Generate tr file for configuration 5 cars / iteration 0
One or more coordinates are negative, some applications might need strictly positive values. To avoid this use the option --shift
```

### Process trips (< 1 minute):

```bash
source scripts/run/processed/mobility.sh
```
Expected output: 
```bash
process finished
```

### Generate raw communication (around 4 minutes):
 
```bash
source scripts/run/raw/communication.sh
```
Expected output: 
```bash
index  25
processing mobility file  1
index  25
processing mobility file  3
index  25
processing mobility file  4
index  25
processing mobility file  0
processing mobility file  8
index  25
```

### Generate processed communication (< 30 seconds):

```bash
source scripts/run/processed/communication.sh
```
Expected output: 
```bash
processing file  3
processing file  5
processing file  0
processing finished
processing finished
processing finished
```

### Generate delay results (< 30 seconds):

Parameters: 

This script selects the clients and generates the communication delay result for different algorithms:
```bash
python src/main.py
```
Expected output: 
```bash
processing model size  500  dataset  8
processing model size  500  dataset  8
processing model size  500  dataset  8
processing model size  500  dataset  8
processing model size  500  dataset  9
processing model size  500  dataset  9
processing model size  500  dataset  9
processing model size  500  dataset  9
processing model size  500  dataset  9
experiments finished
```


The previous python script generates several CSV files, which must be aggregated to be consumed. This can be done by executing the following script:
```bash
python process_results/aggregate_individual_results.py
```

Another process that we should do is the delays per epoch, to show on the graphs:
```bash
python process_results/process_epoch.py
```

# Generate Figures

Training time figure: 

```bash
python generate_figures/communication.py
```

Epoch time figure: 

```bash
python generate_figures/epoch_delays.py
```
This script generates the results located in figures/

Energy figure: 

```bash
python generate_figures/energy.py
```
This script generates the results located on figures/training\_efficiency\_pt.png.

# Paper

[TOFL: Time Optimized Federated Learning](https://www.gta.ufrj.br/ftp/gta/TechReports/SSA25.pdf)

# Cite this work

```bash
@inproceedings{souza2025tofl,
  title={TOFL: Time Optimized Federated Learning},
  author={de Souza, L. A. C., Sammarco, M., Achir, N., Campista, M. E. M., Costa, L. H. M. K.},
  booktitle={XXV Simpósio Brasileiro de Cibersegurança (SBSeg)},
  year={2025},
  organization={SBC}
}
```

# LICENSE

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

